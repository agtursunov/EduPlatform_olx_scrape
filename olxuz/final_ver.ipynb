{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "387df7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54476a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.olx.uz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cea9de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    print(f\"Статус: {response.status_code}\")\n",
    "    return BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac4e6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(soup):\n",
    "    categories = soup.find_all(\"a\", class_=\"css-1gw3rcq\")\n",
    "    next_categories = soup.find_all(\"a\", class_=\"css-1a53ivj\")\n",
    "    categories.extend(next_categories)\n",
    "    \n",
    "    results = []\n",
    "    for cat in categories:\n",
    "        name = cat.get_text(strip=True)\n",
    "        link = cat.get(\"href\")\n",
    "        if link and name:\n",
    "            if not link.startswith(\"http\"):\n",
    "                link = url + link\n",
    "            results.append((name, link))\n",
    "    print(f\"Найдено категорий: {len(results)}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3af7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_categories_to_csv(categories, filename=\"olx_categories.csv\"):\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Категория\", \"Ссылка\"])\n",
    "        writer.writerows(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81c2c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ads(soup):\n",
    "    texts = soup.find_all(\"a\", class_=\"css-1tqlkj0\")\n",
    "    prices = soup.find_all(\"p\", class_=\"css-1vhm4ri\")\n",
    "    locations = soup.find_all(\"p\",class_ =\"css-1pzx3wn\")\n",
    "    dates = soup.find_all(\"p\", class_=\"css-1uf1vew\")\n",
    "    ads = []\n",
    "    for i in range(len(texts)):\n",
    "        title_tag = texts[i]\n",
    "        title = title_tag.get_text(strip=True)\n",
    "\n",
    "        href = title_tag.get(\"href\")\n",
    "        if href:\n",
    "            link = href if href.startswith(\"http\") else url + href\n",
    "        else:\n",
    "            link = 'None'\n",
    "\n",
    "        price = 'None'\n",
    "        price_tag = prices[i].find(\"span\", {\"data-testid\": \"ad-price\"})\n",
    "        str_price = price_tag.get_text(strip=True)\n",
    "        price = str_price if len(str_price) > 0 else 'None'\n",
    "\n",
    "        date_tag = dates[i]\n",
    "        date = date_tag.get_text(strip=True)\n",
    "        \n",
    "        location_tag = locations[i]\n",
    "        location = location_tag.get_text(strip=True)\n",
    "\n",
    "        ads.append((title, price, link, location, date))  \n",
    "    print(f\"Найдено заголовков: {len(texts)}\")\n",
    "    print(f\"Найдено цен: {len(prices)}\")\n",
    "    return ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f694169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ads_to_csv(ads, filename=\"vip_ads.csv\"):\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Объявление\", \"Цена\", \"Ссылка\"])\n",
    "        writer.writerows(ads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "114d2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    soup =  get_soup(url)\n",
    "\n",
    "    categories = get_categories(soup)\n",
    "    save_categories_to_csv(categories)\n",
    "\n",
    "    ads = get_ads(soup)\n",
    "    save_ads_to_csv(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5d1de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус: 200\n",
      "Найдено категорий: 14\n",
      "Найдено заголовков: 14\n",
      "Найдено цен: 14\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
